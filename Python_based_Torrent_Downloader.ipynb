{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Connect to GDrive**"
      ],
      "metadata": {
        "id": "a2Gu78raUY0W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Q0IbUQbXxAf"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Torrent downloader by libtorrent**"
      ],
      "metadata": {
        "id": "zpkpeUAKUojY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLw3dueiqk8e"
      },
      "outputs": [],
      "source": [
        "!apt install python3-libtorrent\n",
        "!pip install libtorrent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfsJe80sqvoF"
      },
      "outputs": [],
      "source": [
        "import libtorrent as lt\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "ses = lt.session()\n",
        "ses.listen_on(6881, 6891)\n",
        "\n",
        "download_path={1:\"/content/\",2:'/content/drive/MyDrive/'}\n",
        "#1. donwload_path[1]:saves locally in Colab\n",
        "#2. download_path[2]:saves files in drive root folder\n",
        "params = {\n",
        "    'save_path': download_path[1],\n",
        "    'storage_mode': lt.storage_mode_t(2),\n",
        "    }\n",
        "\n",
        "#input for magnet link\n",
        "link=\"magnet:?xt=urn:btih:B81FB629E5767C65602D39874B63E2C6943E312D&dn=%5BAnimeRG%5D+Boku+no+Hero+Academia+Season+-+2+%281-25%29+%28My+Hero+Academia+14-38%29+%5B720p%5D+%5BEng+Dubbed%5D+%5BJRR%5D&tr=http%3A%2F%2Fnyaa.tracker.wf%3A7777%2Fannounce&tr=udp%3A%2F%2F9.rarbg.com%3A2740%2Fannounce&tr=udp%3A%2F%2Ftracker.opentrackr.org%3A1337%2Fannounce&tr=udp%3A%2F%2Ftracker.coppersurfer.tk%3A6969%2Fannounce&tr=udp%3A%2F%2Ftracker.openbittorrent.com%3A80%2Fannounce&tr=udp%3A%2F%2Ftracker.zer0day.to%3A1337%2Fannounce&tr=udp%3A%2F%2Ftracker.leechers-paradise.org%3A6969%2Fannounce&tr=udp%3A%2F%2Fcoppersurfer.tk%3A6969%2Fannounce\"\n",
        "\n",
        "# if link ==\"\":link=input()\n",
        "# torrent file praser\n",
        "\n",
        "print(link)\n",
        "\n",
        "handle = lt.add_magnet_uri(ses, link, params)\n",
        "ses.start_dht()\n",
        "\n",
        "begin = time.time()\n",
        "print(datetime.datetime.now())\n",
        "\n",
        "print ('Downloading Metadata...')\n",
        "while (not handle.has_metadata()):\n",
        "    time.sleep(1)\n",
        "print ('Got Metadata, Starting Torrent Download...')\n",
        "\n",
        "print(\"Starting\\n\", handle.name())\n",
        "\n",
        "current_file=str(handle.name())\n",
        "while (handle.status().state != lt.torrent_status.seeding):\n",
        "    s = handle.status()\n",
        "    state_str = ['queued', 'checking', 'downloading metadata', \\\n",
        "            'downloading', 'finished', 'seeding', 'allocating']\n",
        "    print ('\\r%.2f%% complete (down: %.1f kb/s up: %.1f kB/s peers: %d) %s ' % \\\n",
        "            (s.progress * 100, s.download_rate / 1000, s.upload_rate / 1000, \\\n",
        "            s.num_peers, state_str[s.state]),end=\"\")\n",
        "    time.sleep(5)\n",
        "\n",
        "end = time.time()\n",
        "print(handle.name(), \"COMPLETE\")\n",
        "\n",
        "print(\"Elapsed Time: \",int((end-begin)//60),\"min :\", int((end-begin)%60), \"sec\")\n",
        "\n",
        "print(datetime.datetime.now())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPjwOzBFP-Kg"
      },
      "source": [
        "# **MAKING A SINGLE ZIP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5-rQQ8nP_Bf"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "#current_file=\"data\"\n",
        "source=f\"/content/{current_file}\"#\"/content/sample_data\"#\n",
        "dir=download_path[2]#\"/content/\"\n",
        "file_directory=pathlib.Path(source)\n",
        "print(file_directory)\n",
        "\n",
        "remove_option=1\n",
        "#trevarse folder for files and directory\n",
        "with ZipFile(f\"{dir}{current_file}.zip\", mode=\"w\") as ZipAchive:\n",
        "    for file_path in file_directory.rglob(\"*\"):\n",
        "        if \".ipynb_checkpoints\" in str(file_path): continue\n",
        "        print(file_path)\n",
        "        ZipAchive.write(file_path,arcname=file_path.relative_to(file_directory))\n",
        "        if os.path.isfile(file_path) and remove_option:\n",
        "          os.remove(file_path)\n",
        "\n",
        "#print dir\n",
        "with ZipFile(f\"{dir}{current_file}.zip\", mode=\"r\") as archive:\n",
        "    archive.printdir()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUQrO841V0-k"
      },
      "source": [
        "# **SPLITING BINARY FILES**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "current_file=\"Devil May Cry 5 [FitGirl Repack]\"\n",
        "#make headfile.read() as chunks"
      ],
      "metadata": {
        "id": "7WMHs4P3VQKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlGpAHLzIDbc"
      },
      "outputs": [],
      "source": [
        "num=0\n",
        "file_to_zip=f\"/content/{current_file}.zip\"\n",
        "dir_to_save=f\"/content/drive/MyDrive/PART-{num}\"\n",
        "gb=5 # 1-gigabyte use split part under 5gb due to ram limitations for 8gb use below 2gb\n",
        "split_size=int(gb*1024**3)\n",
        "with open (file_to_zip,'rb') as headfile:\n",
        "    filecount=1\n",
        "    while True:\n",
        "        data=headfile.read(split_size)\n",
        "        print(len(data))\n",
        "        if not data:\n",
        "            print(f\"{file_to_zip} finished!\")\n",
        "            break\n",
        "        print(f\"{file_to_zip}.{filecount:03d}\")\n",
        "        if (filecount*gb >= 15):\n",
        "          while True:\n",
        "            x=input(\"change file enter safe:\")\n",
        "            if x == \"safe\":\n",
        "              num+=1\n",
        "              break\n",
        "\n",
        "        with open(f\"{dir_to_save}/{current_file}.{filecount:03d}\",'wb') as zip_part:\n",
        "            zip_part.write(data)\n",
        "            #print(f\"{file_to_zip}{filecount}\")\n",
        "        filecount+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ny7-QpjP9qL"
      },
      "source": [
        "# **Upload to Pixel Drain**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-MiWiefiFCT"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "#Pixeldrainurl =\"https://pixeldrain.com/api/file\"\n",
        "data='/content/sample_data/mnist_train_small.csv'#f\"/content/{current_file}.zip\"#input(\"enter the files path\")\n",
        "files={'file':open(f\"{data}\",'rb')}\n",
        "PostFile=requests.post(url=\"https://pixeldrain.com/api/file\",files=files)\n",
        "print(PostFile.text)\n",
        "import json\n",
        "print(f\"https://pixeldrain.com/u/{json.loads(PostFile.text)['id']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ZIP EXTRACTION**"
      ],
      "metadata": {
        "id": "j6Sb9Z3WT82S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Hp2K9iXsPn5"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "import os\n",
        "# Create a ZipFile Object and load sample.zip in it\n",
        "with ZipFile(f'/content/{currentfile}.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   os.chdir(f'/content/{currentfile}/')\n",
        "   zipObj.extractall()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7 ZIP BASED SPLITING**"
      ],
      "metadata": {
        "id": "CGxhe3w3T2gm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgWx4VUHpOlP",
        "cellView": "code"
      },
      "outputs": [],
      "source": [
        "!sudo apt install p7zip-full p7zip-rar\n",
        "!pip install logzero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WQPzvNxqW4B"
      },
      "outputs": [],
      "source": [
        "#telegram bot. The file size limit is 50MB in upload by telegram bot The file size limit is 1500MB in upload by telegram client but you may add some text or other info so 1495 is more safe\n",
        "\n",
        "#! /usr/bin/python3\n",
        "# -*- coding:utf-8 -*-\n",
        "# apt-get install p7zip-full\n",
        "\n",
        "import subprocess\n",
        "import os\n",
        "import math\n",
        "import logzero\n",
        "import shutil\n",
        "\n",
        "logger = logzero.logger\n",
        "\n",
        "MAX_SPLIT_SIZE = 1495\n",
        "\n",
        "def file_split_7z(file_path, split_size=MAX_SPLIT_SIZE):\n",
        "    file_path_7z_list = []\n",
        "    # if origin file is 7z file rename it\n",
        "    origin_file_path = \"\"\n",
        "    if os.path.splitext(file_path)[1] == \".7z\":\n",
        "        origin_file_path = file_path\n",
        "        file_path = os.path.splitext(origin_file_path)[0] + \".7zo\"\n",
        "        os.rename(origin_file_path, file_path)\n",
        "    # do 7z compress\n",
        "    fz = os.path.getsize(file_path) / 1024 / 1024\n",
        "    pa = math.ceil(fz / split_size)\n",
        "    head, ext = os.path.splitext(os.path.abspath(file_path))\n",
        "    archive_head = \"\".join((head, ext.replace(\".\", \"_\"))) + \".7z\"\n",
        "    for i in range(pa):\n",
        "        check_file_name = \"{}.{:03d}\".format(archive_head, i + 1)\n",
        "        if os.path.isfile(check_file_name):\n",
        "            logger.debug(\"remove exists file | {}\".format(check_file_name))\n",
        "            os.remove(check_file_name)\n",
        "    cmd_7z = [\"7z\", \"a\", \"-v{}m\".format(split_size), \"-y\", \"-mx0\", archive_head, file_path]\n",
        "    proc = subprocess.Popen(cmd_7z, shell=False, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    out, err = proc.communicate()\n",
        "    if b\"Everything is Ok\" not in out:\n",
        "        logger.error(\"7z output | {}\".format(out.decode(\"utf-8\")))\n",
        "        logger.error(\"7z error | {}\".format(err.decode(\"utf-8\")))\n",
        "        return file_path_7z_list\n",
        "\n",
        "    for i in range(pa):\n",
        "        file_path_7z_list.append(\"{}.{:03d}\".format(archive_head, i + 1))\n",
        "    # if origin file is 7z file rename it back\n",
        "    if origin_file_path:\n",
        "        os.rename(file_path, origin_file_path)\n",
        "    return file_path_7z_list\n",
        "\n",
        "def do_file_split(file_path, split_size=MAX_SPLIT_SIZE):\n",
        "    \"\"\"caculate split size\n",
        "        example max split size is 1495 file size is 2000\n",
        "        than the split part num should be int(2000 / 1495 + 0.5) = 2\n",
        "        so the split size should be 1000 + 1000 but not 1495 + 505\n",
        "        with the file size increase the upload risk would be increase too\n",
        "    \"\"\"\n",
        "    file_size = os.path.getsize(file_path) / 2 ** 20\n",
        "    split_part = math.ceil(file_size / split_size)\n",
        "    new_split_size = math.ceil(file_size / split_part)\n",
        "    logger.info(\"file size | {} | split num | {} | split size | {}\".format(file_size, split_part, new_split_size))\n",
        "    return\n",
        "    file_path_7z_list = file_split_7z(file_path, split_size=new_split_size)\n",
        "    return file_path_7z_list\n",
        "print(do_file_split(f\"/content/{current_file}.zip\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}